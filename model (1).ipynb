{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ36S9BWv4hn",
        "outputId": "a2afd8f9-fca4-4dda-d232-8fabc92f6c6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Collecting python-magic\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: python-magic, python-docx, pytesseract, pymupdf\n",
            "Successfully installed pymupdf-1.26.1 pytesseract-0.3.13 python-docx-1.1.2 python-magic-0.4.27\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy matplotlib seaborn python-magic pymupdf python-docx pillow pytesseract openpyxl plotly requests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bva0WErOvovD"
      },
      "outputs": [],
      "source": [
        "# Step 1: Define the environment and import necessary libraries\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import mimetypes\n",
        "import fitz  # PyMuPDF\n",
        "import docx\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import io\n",
        "import base64\n",
        "import json\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "import openpyxl\n",
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2y4skRwPLN6"
      },
      "outputs": [],
      "source": [
        "# Define model ID\n",
        "import os\n",
        "LLAMA_MODEL_ID = \"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\"\n",
        "api_key = st.secrets[\"API_KEY\"]\n",
        "def parse_file(file_path):\n",
        "    mime_type, _ = mimetypes.guess_type(file_path)\n",
        "\n",
        "    if file_path.endswith(\".csv\"):\n",
        "        return pd.read_csv(file_path), \"dataframe\"\n",
        "    elif file_path.endswith(\".xlsx\"):\n",
        "        return pd.read_excel(file_path), \"dataframe\"\n",
        "    elif file_path.endswith(\".txt\"):\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return f.read(), \"text\"\n",
        "    elif file_path.endswith(\".docx\"):\n",
        "        doc = docx.Document(file_path)\n",
        "        return \"\\n\".join([para.text for para in doc.paragraphs]), \"text\"\n",
        "    elif file_path.endswith(\".pdf\"):\n",
        "        doc = fitz.open(file_path)\n",
        "        text = \"\"\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "        return text, \"text\"\n",
        "    elif file_path.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        image = Image.open(file_path)\n",
        "        text = pytesseract.image_to_string(image)\n",
        "        return text, \"text\"\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file type: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "gGK4Pw3Ow1DL"
      },
      "outputs": [],
      "source": [
        "def ask_data_agent(user_question, parsed_content, content_type):\n",
        "    if content_type == \"dataframe\":\n",
        "        data_preview = parsed_content.head(10).to_markdown()\n",
        "        prompt = f\"\"\"You are a smart data analyst.\n",
        "Here is a preview of the dataset (first 10 rows):\n",
        "{data_preview}\n",
        "\n",
        "User question: {user_question}\n",
        "Answer in detail or provide Python code to perform the task.\"\"\"\n",
        "    elif content_type == \"text\":\n",
        "        preview = parsed_content[:2000]\n",
        "        prompt = f\"\"\"You are a document analysis expert.\n",
        "Here is some document content:\n",
        "\\\"\\\"\\\"\n",
        "{preview}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "User question: {user_question}\n",
        "Answer in detail based on the content above.\"\"\"\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported content type\")\n",
        "\n",
        "    return query_llama_agent(prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "C2px9Rt4y6Ht"
      },
      "outputs": [],
      "source": [
        "# Step 4: Define main agent interaction logic\n",
        "\n",
        "def ask_data_agent(user_question, parsed_content, content_type):\n",
        "    \"\"\"\n",
        "    Handle a user's question using the parsed file content and content type.\n",
        "\n",
        "    Parameters:\n",
        "    - user_question: str, natural language question from user\n",
        "    - parsed_content: DataFrame or str, parsed from file\n",
        "    - content_type: \"dataframe\" or \"text\"\n",
        "\n",
        "    Returns:\n",
        "    - Response from LLM agent\n",
        "    \"\"\"\n",
        "    if content_type == \"dataframe\":\n",
        "        # Convert a small preview of the data to string for context\n",
        "        data_preview = parsed_content.head(10).to_markdown()\n",
        "        prompt = f\"\"\"You are a smart data analyst.\n",
        "Here is a preview of the dataset (first 10 rows):\n",
        "{data_preview}\n",
        "\n",
        "User question: {user_question}\n",
        "Answer in detail or provide instructions/code to perform the task.\"\"\"\n",
        "\n",
        "    elif content_type == \"text\":\n",
        "        preview = parsed_content[:2000]  # Truncate to first 2000 characters\n",
        "        prompt = f\"\"\"You are a document analysis expert.\n",
        "Here is some document content:\n",
        "\\\"\\\"\\\"\n",
        "{preview}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "User question: {user_question}\n",
        "Answer in detail based on the content above.\"\"\"\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported content type\")\n",
        "\n",
        "    return query_llama_agent(prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vqzP6Vnc4xSv"
      },
      "outputs": [],
      "source": [
        "# Step 5: Implement LLM code execution inside Jupyter Notebook for plotting if applicable\n",
        "\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def extract_and_run_code(response_text, df):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "\n",
        "    code_blocks = re.findall(r\"```python(.*?)```\", response_text, re.DOTALL)\n",
        "    results = []\n",
        "\n",
        "    for i, code in enumerate(code_blocks):\n",
        "        # 🧹 Clean model code: remove any 'df = pd.read_csv(...)'\n",
        "        cleaned_code = re.sub(r\"df\\s*=\\s*pd\\.read_csv\\(.*?\\)\", \"\", code.strip())\n",
        "\n",
        "        output = f\"\\n▶️ Code Block #{i + 1}:\\n{cleaned_code}\\n\"\n",
        "        try:\n",
        "            exec_globals = {\"pd\": pd, \"plt\": plt, \"df\": df, \"np\": np}\n",
        "            exec(cleaned_code, exec_globals)\n",
        "            fig = plt.gcf()\n",
        "            plt.show(fig)\n",
        "            plt.clf()\n",
        "            output += \"✅ Executed successfully.\"\n",
        "        except Exception as e:\n",
        "            output += f\"⚠️ Execution error: {e}\"\n",
        "\n",
        "        results.append((cleaned_code, output))\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "n0db4foTxWys"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/Delinquency_prediction_dataset.xlsx\"\n",
        "parsed_data, data_type = parse_file(file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56cd62f1"
      },
      "source": [
        "Please upload the `Delinquency_prediction_dataset.csv` file when prompted after running the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GFUk_UmhyPbh",
        "outputId": "b906d832-c942-46b5-b9cd-309c377406ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧾 Raw API Response: {\n",
            "  \"id\": \"nxsdNcj-zqrih-94ec702748689c3c\",\n",
            "  \"object\": \"text.completion\",\n",
            "  \"created\": 1749763708,\n",
            "  \"model\": \"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"text\": \" \\n\\nTo determine which age group has the most income, we need to analyze the 'Income' column in relation to the 'Age_Group' column in the given dataset. \\n\\nHere's a step-by-step guide to achieve this:\\n1. **Group the data by 'Age_Group'**: We will use the pandas library in Python to group the data based on the 'Age_Group' column. This will allow us to perform aggregation operations on the 'Income' column for each age group.\\n\\n2. **Calculate the total or average income for each age group**: We can either sum up the incomes or calculate the average income for each age group. To find which age group has the \\\"most income,\\\" we will calculate the average income, as summing incomes might be biased towards age groups with more customers.\\n\\n3. **Identify the age group with the highest average income**: After calculating the average income for each age group, we will identify the age group with the highest average income.\\n\\nHere's a Python code snippet using pandas that performs these steps:\\n\\n```python\\nimport pandas as pd\\n\\n# Assuming 'df' is your DataFrame\\n# Group by 'Age_Group' and calculate the average 'Income'\\naverage_income_by_age_group = df.groupby('Age_Group')['Income'].mean().reset_index()\\n\\n# Sort the result in descending order based on 'Income'\\naverage_income_by_age_group = average_income_by_age_group.sort_values(by='Income', ascending=False)\\n\\n# The age group with the most income is the first row after sorting\\nage_group_with_most_income = average_income_by_age_group.iloc[0]['Age_Group']\\n\\nprint(f\\\"The age group with the most income is: {age_group_with_most_income}\\\")\\nprint(average_income_by_age_group)\\n```\\n\\nThis code will output the age group with the highest average income and display a sorted table of average incomes by age group.\\n\\nTo directly execute this task, ensure you have pandas installed (`pip install pandas`), and then run the provided Python code with your dataset loaded into a DataFrame named `df`. \\n\\nFor example, if your data is in a CSV file named `data.csv`, you can load it into `df` using:\\n```python\\ndf = pd.read_csv('data.csv')\\n```\",\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"stop_reason\": null,\n",
            "      \"prompt_logprobs\": null\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1194,\n",
            "    \"total_tokens\": 1645,\n",
            "    \"completion_tokens\": 451,\n",
            "    \"prompt_tokens_details\": null\n",
            "  },\n",
            "  \"prompt\": []\n",
            "}\n",
            "To determine which age group has the most income, we need to analyze the 'Income' column in relation to the 'Age_Group' column in the given dataset. \n",
            "\n",
            "Here's a step-by-step guide to achieve this:\n",
            "1. **Group the data by 'Age_Group'**: We will use the pandas library in Python to group the data based on the 'Age_Group' column. This will allow us to perform aggregation operations on the 'Income' column for each age group.\n",
            "\n",
            "2. **Calculate the total or average income for each age group**: We can either sum up the incomes or calculate the average income for each age group. To find which age group has the \"most income,\" we will calculate the average income, as summing incomes might be biased towards age groups with more customers.\n",
            "\n",
            "3. **Identify the age group with the highest average income**: After calculating the average income for each age group, we will identify the age group with the highest average income.\n",
            "\n",
            "Here's a Python code snippet using pandas that performs these steps:\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "\n",
            "# Assuming 'df' is your DataFrame\n",
            "# Group by 'Age_Group' and calculate the average 'Income'\n",
            "average_income_by_age_group = df.groupby('Age_Group')['Income'].mean().reset_index()\n",
            "\n",
            "# Sort the result in descending order based on 'Income'\n",
            "average_income_by_age_group = average_income_by_age_group.sort_values(by='Income', ascending=False)\n",
            "\n",
            "# The age group with the most income is the first row after sorting\n",
            "age_group_with_most_income = average_income_by_age_group.iloc[0]['Age_Group']\n",
            "\n",
            "print(f\"The age group with the most income is: {age_group_with_most_income}\")\n",
            "print(average_income_by_age_group)\n",
            "```\n",
            "\n",
            "This code will output the age group with the highest average income and display a sorted table of average incomes by age group.\n",
            "\n",
            "To directly execute this task, ensure you have pandas installed (`pip install pandas`), and then run the provided Python code with your dataset loaded into a DataFrame named `df`. \n",
            "\n",
            "For example, if your data is in a CSV file named `data.csv`, you can load it into `df` using:\n",
            "```python\n",
            "df = pd.read_csv('data.csv')\n",
            "```\n",
            "The age group with the most income is: 55-64\n",
            "  Age_Group         Income\n",
            "4     55-64  111971.500000\n",
            "0     18-24  110727.845070\n",
            "2     35-44  110653.000000\n",
            "3     45-54  110644.532609\n",
            "5       65+  104778.408451\n",
            "1     25-34   98594.852459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<string>:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[('import pandas as pd\\n\\n# Assuming \\'df\\' is your DataFrame\\n# Group by \\'Age_Group\\' and calculate the average \\'Income\\'\\naverage_income_by_age_group = df.groupby(\\'Age_Group\\')[\\'Income\\'].mean().reset_index()\\n\\n# Sort the result in descending order based on \\'Income\\'\\naverage_income_by_age_group = average_income_by_age_group.sort_values(by=\\'Income\\', ascending=False)\\n\\n# The age group with the most income is the first row after sorting\\nage_group_with_most_income = average_income_by_age_group.iloc[0][\\'Age_Group\\']\\n\\nprint(f\"The age group with the most income is: {age_group_with_most_income}\")\\nprint(average_income_by_age_group)',\n",
              "  '\\n▶️ Code Block #1:\\nimport pandas as pd\\n\\n# Assuming \\'df\\' is your DataFrame\\n# Group by \\'Age_Group\\' and calculate the average \\'Income\\'\\naverage_income_by_age_group = df.groupby(\\'Age_Group\\')[\\'Income\\'].mean().reset_index()\\n\\n# Sort the result in descending order based on \\'Income\\'\\naverage_income_by_age_group = average_income_by_age_group.sort_values(by=\\'Income\\', ascending=False)\\n\\n# The age group with the most income is the first row after sorting\\nage_group_with_most_income = average_income_by_age_group.iloc[0][\\'Age_Group\\']\\n\\nprint(f\"The age group with the most income is: {age_group_with_most_income}\")\\nprint(average_income_by_age_group)\\n✅ Executed successfully.'),\n",
              " ('', '\\n▶️ Code Block #2:\\n\\n✅ Executed successfully.')]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = ask_data_agent(\"which age group has the most income\", parsed_data, data_type)\n",
        "print(response)\n",
        "extract_and_run_code(response, parsed_data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
